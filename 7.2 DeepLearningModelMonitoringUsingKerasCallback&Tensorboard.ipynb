{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-93f7e17dc938>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m ]\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m model.fit(x, y, \n\u001b[0;32m     17\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#ModelCheckpoint, EarlyStopping callback\n",
    "import keras\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=1,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='my_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(x, y, \n",
    "          epochs=10,\n",
    "         batch_size=32,\n",
    "         callbacks=callbacks_list,\n",
    "         validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReduceLROnPlateau callback\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=10,\n",
    "    )\n",
    "]\n",
    "\n",
    "#Making my own callback\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "    \n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input, layer_outputs)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError('Requires validation_data.')\n",
    "            \n",
    "        validation_sample = self.validation_data[0][0:1]\n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        f = open('activations_at_epoch' + str(epoch) + 'npz', 'wb')\n",
    "        np.savez(f, activations)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "  1/157 [..............................] - ETA: 0s - loss: 3.8092 - acc: 0.5781WARNING:tensorflow:From C:\\Users\\bronto\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.6302 - acc: 0.6550 - val_loss: 0.5155 - val_acc: 0.8066\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.4627 - acc: 0.8495 - val_loss: 0.4400 - val_acc: 0.8618\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 26s 169ms/step - loss: 0.3852 - acc: 0.8830 - val_loss: 0.4876 - val_acc: 0.8620\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.3275 - acc: 0.9021 - val_loss: 0.4963 - val_acc: 0.8644\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.2933 - acc: 0.9200 - val_loss: 0.4829 - val_acc: 0.8646\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.2453 - acc: 0.9377 - val_loss: 0.6120 - val_acc: 0.8682\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.2085 - acc: 0.9555 - val_loss: 0.7491 - val_acc: 0.8576\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.1834 - acc: 0.9643 - val_loss: 0.8071 - val_acc: 0.8590\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.1496 - acc: 0.9775 - val_loss: 0.8483 - val_acc: 0.8620\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 24s 154ms/step - loss: 0.1276 - acc: 0.9858 - val_loss: 0.9155 - val_acc: 0.8644\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.1125 - acc: 0.9894 - val_loss: 1.1256 - val_acc: 0.8568\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.1064 - acc: 0.9901 - val_loss: 1.1369 - val_acc: 0.8596\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 24s 153ms/step - loss: 0.1074 - acc: 0.9898 - val_loss: 1.0914 - val_acc: 0.8646\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.1069 - acc: 0.9905 - val_loss: 1.3807 - val_acc: 0.8398\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 24s 154ms/step - loss: 0.1041 - acc: 0.9902 - val_loss: 1.1963 - val_acc: 0.8568\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 24s 154ms/step - loss: 0.0984 - acc: 0.9918 - val_loss: 1.2444 - val_acc: 0.8624\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.0983 - acc: 0.9915 - val_loss: 1.2391 - val_acc: 0.8596\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 24s 154ms/step - loss: 0.0988 - acc: 0.9915 - val_loss: 1.2196 - val_acc: 0.8604\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 24s 153ms/step - loss: 0.0997 - acc: 0.9923 - val_loss: 1.2887 - val_acc: 0.8592\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 24s 153ms/step - loss: 0.0972 - acc: 0.9919 - val_loss: 1.5576 - val_acc: 0.8456\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import os\n",
    "\n",
    "max_features = 2000\n",
    "max_len = 500\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len, name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "os.mkdir('my_log_dir')\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='my_log_dir',\n",
    "        histogram_freq=1,\n",
    "        embeddings_freq=1,\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
