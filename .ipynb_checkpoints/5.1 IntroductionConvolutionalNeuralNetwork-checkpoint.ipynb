{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 20s 22ms/step - loss: 0.1738 - accuracy: 0.9444\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0465 - accuracy: 0.9859\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0327 - accuracy: 0.9900\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.0251 - accuracy: 0.9926\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 20s 22ms/step - loss: 0.0198 - accuracy: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15ac724ba90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0300 - accuracy: 0.9906\n",
      "0.9905999898910522\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On the example in 2.1, we have got 0.9779 accuracy. We have decreased about 58% of error (relatively).\n",
    "\n",
    "\"\"\"\n",
    "Convolution\n",
    "The fundamental difference between fully connected layer and convolutional layer is the following. Dense layer learns global pattern in\n",
    "input attribute space, while convolutional layer learns local pattern. In image, it finds the pattern with small 2D window from input.\n",
    "This fundamental attribute provides ConvNet two interesting properties:\n",
    "1. Learned pattern gets translation invariance: If the ConvNet learned some pattern at the left bottom corner of some image, it can\n",
    "detect the pattern from other space (such as left top corner). Fully connected network has to learn this as a new pattern rather \n",
    "recognizing as an existing pattern. This property makes ConvNet process the image efficiently. (fundamentally what we see is not\n",
    "recognized differently just because of translation). It can learn expression that has generalization ability with relatively small \n",
    "number of samples.\n",
    "2. ConvNet can learn spatial hierarchical structure of the pattern: First convolutional layer learns small local pattern such as edge.\n",
    "Second convolutional layer learns bigger pattern consisted of patterns of first layer, etc. By using this method ConvNet can efficiently\n",
    "learn complicated and abstract visual concepts (fundamentally the world we see has spatial hierarchial structure)\n",
    "\n",
    "Convolution operation is applied to 3D tensor called feature map. This tensor is consisted of 2 spatial axis (height, width) and 1\n",
    "depth axis (or channel axis). Since RGB image has 3 color channels (red, green, blue), dimension of its depth axis becomes 3. Dimension\n",
    "of depth axis of black and white images like MNIST images is 1 (gray tone).Convolution operation extracts small patches from input\n",
    "feature map and creates output feature map by applying same conversion to all of these patches.\n",
    "\n",
    "Output feature map is also a 3D tensor that has height and width. Depth of output tensor depends on the situation since it is decided by\n",
    "the layer's parameters. Then channels of depth axis do not longer mean specific color like RGB. Instead, it means some kind of filter.\n",
    "Filter encodes some feature of input data. For example, one filter can encode if there exists a face in input.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
